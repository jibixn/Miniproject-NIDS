{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a6f9f34-928d-42cc-a712-becc4d70ac72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler,LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b778fd0e-08fa-471d-acce-23115be3f4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    ds = []\n",
    "    for root, dirs, files in os.walk('CIC dataset/'):\n",
    "        for file in files:            \n",
    "            ds.append(pd.read_csv(os.path.join(root,file)))\n",
    "    # for i, data in enumerate(ds, start=1):\n",
    "    #     rows, cols = data.shape\n",
    "    #     print(f'ds{i} -> {rows} rows, {cols} columns')\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9cbff917-e831-41ef-afa7-d832326e9943",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(datas):    \n",
    "    #merging data\n",
    "    data = pd.concat(datas, axis = 0, ignore_index = True)\n",
    "    print(f\"Before duplicate removal{data.shape}\")\n",
    "\n",
    "    #remove leading or trailing whitespace from col names\n",
    "    col_names = {col: col.strip() for col in data.columns}\n",
    "    data.rename(columns = col_names, inplace = True)\n",
    "    \n",
    "    #duplicate rows removal\n",
    "    data = data.drop_duplicates(keep = 'first')\n",
    "    \n",
    "    #duplicate columns removal\n",
    "    columns = data.columns\n",
    "    identical_columns =[]\n",
    "    list_control = columns.copy().tolist()\n",
    "    for col1 in columns:\n",
    "        for col2 in columns:\n",
    "            if(col1!=col2):\n",
    "                if(data[col1].equals(data[col2])):\n",
    "                    if(col2 not in identical_columns and col2 in list_control):\n",
    "                        identical_columns.append(col2)\n",
    "                        if col1 in list_control:\n",
    "                            list_control.remove(col1)\n",
    "                        if col2 in list_control: \n",
    "                            list_control.remove(col2)\n",
    "                    elif(col2 in identical_columns and col2 in list_control):\n",
    "                        if col2 in list_control: \n",
    "                            list_control.remove(col2)    \n",
    "    for col in identical_columns:\n",
    "        data.drop(columns = col, inplace = True)\n",
    "                    \n",
    "    print(f\"After duplicate removal{data.shape}\")\n",
    "    \n",
    "    # Treating infinite values\n",
    "    data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    \n",
    "    #removing rows with missing values\n",
    "    missing_rows = data.isna().any(axis=1).sum()\n",
    "    print(f'\\nTotal rows with missing values: {missing_rows}')\n",
    "    data = data.dropna()\n",
    "    nan_count = data.isnull().sum().sum()\n",
    "    print(f\"Total NaN values: {nan_count}\")\n",
    "    \n",
    "\n",
    "    \n",
    "    print(f\"After missing value rows' removal{data.shape}\")\n",
    "    \n",
    "    #splitting data\n",
    "    target = data['Label']\n",
    "    features = data.drop('Label',axis = 1)\n",
    "\n",
    "    \n",
    "    return features,target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e591a9cd-cfa2-48cc-8ba0-da15bf3f0550",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_data(data):\n",
    "    encoder = LabelEncoder()\n",
    "    for col in data.columns:\n",
    "        if(data[col].dtype == 'object'):\n",
    "            data[col] = encoder.fit_transform(data[col])\n",
    "    nan_count = data.isnull().sum().sum()\n",
    "    print(f\"Total NaN values: {nan_count}\")\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8155665a-19c0-4162-85d0-85acae6016bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_data(data):\n",
    "    scaler = StandardScaler()\n",
    "    nan_count = data.isnull().sum().sum()\n",
    "    print(f\"Total NaN values: {nan_count}\")\n",
    "    return scaler.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "53d96a9e-e6d0-41b5-a9bd-7d4b898c1459",
   "metadata": {},
   "outputs": [],
   "source": [
    "def oversample(data,target):\n",
    "    sampler = RandomOverSampler(sampling_strategy = 'minority')\n",
    "    new_data,new_target = sampler.fit_resample(data,target)\n",
    "    return new_data, new_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ae506bfd-d7d7-4e4b-acfe-d267fd754db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dimensionality_reduction(data):    \n",
    "    pca = PCA(n_components = 10)\n",
    "    data = pca.fit_transform(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "acddadb1-ce1c-4721-8902-243467d54815",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree(features, labels, test_x, test_y):\n",
    "    classifier = tree.DecisionTreeClassifier()\n",
    "    classifier.fit(features,labels)\n",
    "    # tree.plot_tree(classifier, max_depth = 3)\n",
    "    predictions = classifier.predict(test_x)\n",
    "    accuracy = accuracy_score(test_y, predictions)\n",
    "    report = classification_report(test_y, predictions) \n",
    "    print(f\"Accuracy = {accuracy*100:.2f}%\")\n",
    "    print(f\"Report = \\n{report}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "98d520bb-5997-451b-b101-2d2a4e0cb1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extra_tree(features, labels, test_x, test_y):\n",
    "    classifier = ExtraTreesClassifier(n_estimators = 100)\n",
    "    classifier.fit(features,labels)\n",
    "    predictions = classifier.predict(test_x)\n",
    "    accuracy = accuracy_score(test_y, predictions)\n",
    "    report = classification_report(test_y, predictions,zero_division=1) \n",
    "    print(f\"Accuracy = {accuracy*100:.2f}%\")\n",
    "    print(f\"Report = \\n{report}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6970a2b4-7fe6-4047-94ff-fdb6ca41ca1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest(features,labels,test_x,test_y):\n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "    model.fit(features,labels)\n",
    "    y_pred = model.predict(test_x)\n",
    "    accuracy = accuracy_score(test_y, y_pred)\n",
    "    report = classification_report(test_y, y_pred) \n",
    "    print(f\"Accuracy = {accuracy*100:.2f}%\")\n",
    "    print(f\"Report = \\n{report}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dffc1136-3a50-435d-b33a-5fd22d6bccd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xg_boost(features,labels,test_x,test_y):\n",
    "    encoder = LabelEncoder()\n",
    "    labels = encoder.fit_transform(labels)\n",
    "    model = xgb.XGBClassifier(n_estimators=100, random_state=42, eval_metric='logloss')\n",
    "    model.fit(features,labels)    \n",
    "    y_pred = model.predict(test_x)\n",
    "    y_pred = encoder.inverse_transform(y_pred)\n",
    "    accuracy = accuracy_score(test_y, y_pred)\n",
    "    report = classification_report(test_y, y_pred) \n",
    "    print(f\"Accuracy = {accuracy*100:.2f}%\")\n",
    "    print(f\"Report = \\n{report}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2bb25219-eb0d-4f4a-948f-e53cb9d19a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a7753987-2883-4d8f-a999-4a74d57a1671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before duplicate removal(2830743, 79)\n",
      "After duplicate removal(2522362, 67)\n",
      "\n",
      "Total rows with missing values: 1564\n",
      "Total NaN values: 0\n",
      "After missing value rows' removal(2520798, 67)\n"
     ]
    }
   ],
   "source": [
    "ds,target = preprocess_data(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e37af536-bd34-4915-8b71-7c76b18554ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total NaN values: 0\n"
     ]
    }
   ],
   "source": [
    "#convert categorical values to numerical\n",
    "ds = encode_data(ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f63dad4d-352a-434c-a59a-52d993d36306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total NaN values: 0\n"
     ]
    }
   ],
   "source": [
    "ds = standardize_data(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9a30cd23-ef75-4c2f-b899-5ecaaa67adb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DS shape: (4615844, 66)\n"
     ]
    }
   ],
   "source": [
    "ds,target = oversample(ds,target)\n",
    "print(\"DS shape:\", ds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8f884449-94f5-481d-9587-8243a5997955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DS shape: (4615844, 10)\n",
      "[[-9.391733042772035 -1.4885218981248967 0.30573379927038197 ...\n",
      "  0.3086472829402057 1.202258193044035 'BENIGN']\n",
      " [-9.446597292207212 -1.3940009084895517 0.3474006533995247 ...\n",
      "  0.07126294603859569 0.1288730586153206 'BENIGN']\n",
      " [-9.451636767530381 -1.4037605042776762 0.3482254797973143 ...\n",
      "  0.07837223013809293 0.1735682121850627 'BENIGN']\n",
      " ...\n",
      " [9.570191114273825 -0.8656602868530375 1.7740940933240172 ...\n",
      "  -0.2884728021043731 -0.3574906540451769 'Heartbleed']\n",
      " [9.417715287688385 0.5198730492562421 -3.7501907615218113 ...\n",
      "  -0.09989450475945823 1.3177310346067617 'Heartbleed']\n",
      " [10.1138700221222 -0.3453769415588933 -0.3312021000360078 ...\n",
      "  -0.1968264473742694 0.3842307603762942 'Heartbleed']]\n"
     ]
    }
   ],
   "source": [
    "ds = dimensionality_reduction(ds)\n",
    "print(\"DS shape:\", ds.shape)\n",
    "ds = np.column_stack((ds,target))\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f45d515e-4303-4a5f-91b7-14e4c3902ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(ds, test_size = 0.2)\n",
    "# test_data = np.delete(test_data, 10,1)\n",
    "x_train = train_data[:,:-1]\n",
    "y_train = train_data[:,-1]\n",
    "x_test = test_data[:,:-1]\n",
    "y_test = test_data[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e225af52-3917-41b0-8145-686f513e923c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 99.81%\n",
      "Report = \n",
      "                            precision    recall  f1-score   support\n",
      "\n",
      "                    BENIGN       1.00      1.00      1.00    419448\n",
      "                       Bot       0.62      0.64      0.63       377\n",
      "                      DDoS       1.00      1.00      1.00     25466\n",
      "             DoS GoldenEye       0.97      0.96      0.96      2058\n",
      "                  DoS Hulk       1.00      1.00      1.00     34573\n",
      "          DoS Slowhttptest       0.98      0.99      0.98      1115\n",
      "             DoS slowloris       0.99      0.98      0.99      1043\n",
      "               FTP-Patator       1.00      1.00      1.00      1220\n",
      "                Heartbleed       1.00      1.00      1.00    418522\n",
      "              Infiltration       0.50      0.43      0.46         7\n",
      "                  PortScan       0.98      0.98      0.98     18208\n",
      "               SSH-Patator       0.97      0.98      0.97       684\n",
      "  Web Attack � Brute Force       0.72      0.73      0.73       307\n",
      "Web Attack � Sql Injection       0.20      0.25      0.22         4\n",
      "          Web Attack � XSS       0.40      0.39      0.39       137\n",
      "\n",
      "                  accuracy                           1.00    923169\n",
      "                 macro avg       0.82      0.82      0.82    923169\n",
      "              weighted avg       1.00      1.00      1.00    923169\n",
      "\n"
     ]
    }
   ],
   "source": [
    "decision_tree(x_train,y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "dcb7ea63-3bdd-4ac8-85db-8b71e1883dd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 99.87%\n",
      "Report = \n",
      "                            precision    recall  f1-score   support\n",
      "\n",
      "                    BENIGN       1.00      1.00      1.00    419448\n",
      "                       Bot       0.77      0.62      0.69       377\n",
      "                      DDoS       1.00      1.00      1.00     25466\n",
      "             DoS GoldenEye       1.00      0.98      0.99      2058\n",
      "                  DoS Hulk       1.00      1.00      1.00     34573\n",
      "          DoS Slowhttptest       0.99      0.99      0.99      1115\n",
      "             DoS slowloris       0.99      0.99      0.99      1043\n",
      "               FTP-Patator       1.00      1.00      1.00      1220\n",
      "                Heartbleed       1.00      1.00      1.00    418522\n",
      "              Infiltration       0.83      0.71      0.77         7\n",
      "                  PortScan       0.99      0.99      0.99     18208\n",
      "               SSH-Patator       0.97      0.98      0.97       684\n",
      "  Web Attack � Brute Force       0.75      0.76      0.76       307\n",
      "Web Attack � Sql Injection       0.50      0.25      0.33         4\n",
      "          Web Attack � XSS       0.48      0.42      0.45       137\n",
      "\n",
      "                  accuracy                           1.00    923169\n",
      "                 macro avg       0.88      0.85      0.86    923169\n",
      "              weighted avg       1.00      1.00      1.00    923169\n",
      "\n"
     ]
    }
   ],
   "source": [
    "extra_tree(x_train,y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "aa20e8aa-fb57-4aa8-85a7-6e03c9dd2198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 99.87%\n",
      "Report = \n",
      "                            precision    recall  f1-score   support\n",
      "\n",
      "                    BENIGN       1.00      1.00      1.00    419448\n",
      "                       Bot       0.79      0.58      0.67       377\n",
      "                      DDoS       1.00      1.00      1.00     25466\n",
      "             DoS GoldenEye       1.00      0.98      0.99      2058\n",
      "                  DoS Hulk       1.00      1.00      1.00     34573\n",
      "          DoS Slowhttptest       0.99      0.99      0.99      1115\n",
      "             DoS slowloris       1.00      0.99      0.99      1043\n",
      "               FTP-Patator       1.00      1.00      1.00      1220\n",
      "                Heartbleed       1.00      1.00      1.00    418522\n",
      "              Infiltration       0.67      0.29      0.40         7\n",
      "                  PortScan       0.99      0.99      0.99     18208\n",
      "               SSH-Patator       0.98      0.98      0.98       684\n",
      "  Web Attack � Brute Force       0.75      0.77      0.76       307\n",
      "Web Attack � Sql Injection       1.00      0.25      0.40         4\n",
      "          Web Attack � XSS       0.46      0.39      0.42       137\n",
      "\n",
      "                  accuracy                           1.00    923169\n",
      "                 macro avg       0.91      0.81      0.84    923169\n",
      "              weighted avg       1.00      1.00      1.00    923169\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random_forest(x_train,y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "537dcc23-2277-4ca5-a8ee-5b2388724976",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Mix of label input types (string and number)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[50], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m xg_boost(x_train,y_train, x_test, y_test)\n",
      "Cell \u001b[1;32mIn[48], line 9\u001b[0m, in \u001b[0;36mxg_boost\u001b[1;34m(features, labels, test_x, test_y)\u001b[0m\n\u001b[0;32m      7\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(test_x)\n\u001b[0;32m      8\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(test_y, y_pred)\n\u001b[1;32m----> 9\u001b[0m report \u001b[38;5;241m=\u001b[39m classification_report(test_y, y_pred) \n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReport = \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mreport\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:2629\u001b[0m, in \u001b[0;36mclassification_report\u001b[1;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[0;32m   2626\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[0;32m   2628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 2629\u001b[0m     labels \u001b[38;5;241m=\u001b[39m unique_labels(y_true, y_pred)\n\u001b[0;32m   2630\u001b[0m     labels_given \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   2631\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:114\u001b[0m, in \u001b[0;36munique_labels\u001b[1;34m(*ys)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;66;03m# Check that we don't mix string type with number type\u001b[39;00m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(label, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m ys_labels)) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 114\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMix of label input types (string and number)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(\u001b[38;5;28msorted\u001b[39m(ys_labels))\n",
      "\u001b[1;31mValueError\u001b[0m: Mix of label input types (string and number)"
     ]
    }
   ],
   "source": [
    "xg_boost(x_train,y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92ecb86-ae59-4f3f-bb53-7eb9020edb33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a6f9f34-928d-42cc-a712-becc4d70ac72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler,LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b778fd0e-08fa-471d-acce-23115be3f4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    ds = []\n",
    "    for root, dirs, files in os.walk('CIC dataset/'):\n",
    "        for file in files:            \n",
    "            ds.append(pd.read_csv(os.path.join(root,file)))\n",
    "    # for i, data in enumerate(ds, start=1):\n",
    "    #     rows, cols = data.shape\n",
    "    #     print(f'ds{i} -> {rows} rows, {cols} columns')\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9cbff917-e831-41ef-afa7-d832326e9943",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(datas):    \n",
    "    #merging data\n",
    "    data = pd.concat(datas, axis = 0, ignore_index = True)\n",
    "    print(f\"Before duplicate removal{data.shape}\")\n",
    "\n",
    "    #remove leading or trailing whitespace from col names\n",
    "    col_names = {col: col.strip() for col in data.columns}\n",
    "    data.rename(columns = col_names, inplace = True)\n",
    "    \n",
    "    #duplicate rows removal\n",
    "    data = data.drop_duplicates(keep = 'first')\n",
    "    \n",
    "    #duplicate columns removal\n",
    "    columns = data.columns\n",
    "    identical_columns =[]\n",
    "    list_control = columns.copy().tolist()\n",
    "    for col1 in columns:\n",
    "        for col2 in columns:\n",
    "            if(col1!=col2):\n",
    "                if(data[col1].equals(data[col2])):\n",
    "                    if(col2 not in identical_columns and col2 in list_control):\n",
    "                        identical_columns.append(col2)\n",
    "                        if col1 in list_control:\n",
    "                            list_control.remove(col1)\n",
    "                        if col2 in list_control: \n",
    "                            list_control.remove(col2)\n",
    "                    elif(col2 in identical_columns and col2 in list_control):\n",
    "                        if col2 in list_control: \n",
    "                            list_control.remove(col2)    \n",
    "    for col in identical_columns:\n",
    "        data.drop(columns = col, inplace = True)\n",
    "                    \n",
    "    print(f\"After duplicate removal{data.shape}\")\n",
    "    \n",
    "    # Treating infinite values\n",
    "    data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    \n",
    "    #removing rows with missing values\n",
    "    missing_rows = data.isna().any(axis=1).sum()\n",
    "    print(f'\\nTotal rows with missing values: {missing_rows}')\n",
    "    data = data.dropna()\n",
    "    nan_count = data.isnull().sum().sum()\n",
    "    print(f\"Total NaN values: {nan_count}\")\n",
    "    \n",
    "\n",
    "    \n",
    "    print(f\"After missing value rows' removal{data.shape}\")\n",
    "    \n",
    "    #splitting data\n",
    "    target = data['Label']\n",
    "    features = data.drop('Label',axis = 1)\n",
    "\n",
    "    \n",
    "    return features,target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e591a9cd-cfa2-48cc-8ba0-da15bf3f0550",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_data(data):\n",
    "    encoder = LabelEncoder()\n",
    "    for col in data.columns:\n",
    "        if(data[col].dtype == 'object'):\n",
    "            data[col] = encoder.fit_transform(data[col])\n",
    "    nan_count = data.isnull().sum().sum()\n",
    "    print(f\"Total NaN values: {nan_count}\")\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8155665a-19c0-4162-85d0-85acae6016bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_data(data):\n",
    "    scaler = StandardScaler()\n",
    "    nan_count = data.isnull().sum().sum()\n",
    "    print(f\"Total NaN values: {nan_count}\")\n",
    "    return scaler.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "53d96a9e-e6d0-41b5-a9bd-7d4b898c1459",
   "metadata": {},
   "outputs": [],
   "source": [
    "def oversample(data,target):\n",
    "    sampler = RandomOverSampler(sampling_strategy = 'minority')\n",
    "    new_data,new_target = sampler.fit_resample(data,target)\n",
    "    # nan_count1 = new_data.isnull().sum().sum()\n",
    "    # nan_count2 = new_target.isnull().sum().sum()\n",
    "    # print(f\"Total NaN values: {nan_count1} and {nan_count2}\")\n",
    "    return new_data, new_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ae506bfd-d7d7-4e4b-acfe-d267fd754db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dimensionality_reduction(data):    \n",
    "    pca = PCA(n_components = 10)\n",
    "    data = pca.fit_transform(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "2bb25219-eb0d-4f4a-948f-e53cb9d19a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a7753987-2883-4d8f-a999-4a74d57a1671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before duplicate removal(2830743, 79)\n",
      "After duplicate removal(2522362, 67)\n",
      "\n",
      "Total rows with missing values: 1564\n",
      "Total NaN values: 0\n",
      "After missing value rows' removal(2520798, 67)\n"
     ]
    }
   ],
   "source": [
    "ds,target = preprocess_data(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e37af536-bd34-4915-8b71-7c76b18554ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total NaN values: 0\n"
     ]
    }
   ],
   "source": [
    "#convert categorical values to numerical\n",
    "ds = encode_data(ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f63dad4d-352a-434c-a59a-52d993d36306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total NaN values: 0\n"
     ]
    }
   ],
   "source": [
    "ds = standardize_data(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "9a30cd23-ef75-4c2f-b899-5ecaaa67adb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DS shape: (4615844, 66)\n"
     ]
    }
   ],
   "source": [
    "ds,target = oversample(ds,target)\n",
    "print(\"DS shape:\", ds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "8f884449-94f5-481d-9587-8243a5997955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DS shape: (4615844, 10)\n",
      "[[-9.391921378760898 -1.4883970670263669 0.30493449192343525 ...\n",
      "  0.308196144176769 1.2019175605294312 'BENIGN']\n",
      " [-9.446783439909952 -1.3938679943699754 0.34661147170050716 ...\n",
      "  0.07074958490174506 0.12941947086699673 'BENIGN']\n",
      " [-9.451822676845193 -1.4036276280504745 0.34743192784465843 ...\n",
      "  0.07784218922063342 0.17410161288864634 'BENIGN']\n",
      " ...\n",
      " [10.14514157106182 -0.808184803707598 1.5108635165132378 ...\n",
      "  -0.2629479478411217 -0.17647008859623287 'Heartbleed']\n",
      " [10.14514157106182 -0.808184803707598 1.5108635165132378 ...\n",
      "  -0.2629479478411217 -0.17647008859623287 'Heartbleed']\n",
      " [6.564105103767575 -0.9692230556128578 2.647245341865279 ...\n",
      "  1.6110263372755547 -0.7795092655115883 'Heartbleed']]\n"
     ]
    }
   ],
   "source": [
    "ds = dimensionality_reduction(ds)\n",
    "print(\"DS shape:\", ds.shape)\n",
    "ds = np.column_stack((ds,target))\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45d515e-4303-4a5f-91b7-14e4c3902ab0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
